# Code Review

Ревью выполнено в рамках второго спринта второго модуля.
Так как проект выполняется индивидуально, ревью проведено на собственный код
из спринта ETL и первого спринта модуля «Сервис Async API».

---

## Review 1 — Async API (FastAPI + Elasticsearch + Redis)

### Что сделано хорошо
- Чёткое разделение слоёв: API / Service / Storage.
- Использование асинхронных клиентов Elasticsearch и Redis.
- Реализовано кеширование ответов с использованием Redis.
- Используются Pydantic-модели для валидации и сериализации данных.
- Добавлена пагинация и сортировка в эндпоинтах.

### Что можно улучшить
- Изначально использовались `try/except Exception: pass` — это может скрывать реальные ошибки.
- Отсутствовал механизм повторных попыток (retry) при временной недоступности внешних сервисов.

### Что было улучшено
- Добавлен exponential backoff для работы с Elasticsearch и Redis.
- Исключения стали обрабатываться более явно и предсказуемо.
- Конфигурация вынесена в класс Settings с валидацией через Pydantic.

### Отдельное замечание — работа с UUID и алиасами

В процессе разработки была выявлена неоднозначность в использовании поля идентификатора фильма:
в Elasticsearch документ хранится с полем `_id`, а в API используется поле `uuid`.

Изначально API возвращал поле `id`, что приводило к несоответствию контракту
и падению функциональных тестов.

Что было сделано:
- В Pydantic-моделях добавлен алиас `uuid = Field(alias="id")`.
- Включён `populate_by_name = True` для корректной сериализации.
- Контракт API унифицирован: во всех ответах клиенту возвращается поле `uuid`.

Результат:
- API соответствует документации.
- Функциональные тесты проходят стабильно.
- Исключена неоднозначность между `_id`, `id` и `uuid`.

---

## Review 2 — ETL (PostgreSQL → Elasticsearch)

### Что сделано хорошо
- Реализована инкрементальная загрузка данных.
- Используется состояние (state) для сохранения прогресса ETL.
- Корректно обрабатываются связи фильмов, жанров и персон.

### Что можно улучшить
- Можно добавить логирование шагов ETL для упрощения отладки.
- Возможна оптимизация bulk-запросов при загрузке больших объёмов данных.

### Итог
Код соответствует требованиям задания, архитектура читаемая,
основные ошибки первого спринта были устранены.

---

## Общий вывод

Код готов к дальнейшему расширению, хорошо масштабируется и
соответствует требованиям по отказоустойчивости и производительности.